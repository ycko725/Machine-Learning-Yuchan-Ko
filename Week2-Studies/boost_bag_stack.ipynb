{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f3b8b3c",
   "metadata": {},
   "source": [
    "# Practicing Using the Following Kaggle Notebook\n",
    "Boosting, Bagging, Stacking <br />\n",
    "https://www.kaggle.com/code/arthurtok/introduction-to-ensembling-stacking-in-python <br />\n",
    "https://www.kaggle.com/code/vbmokin/autoselection-from-20-classifier-models-l-curves#7.-Prediction-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7566aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, StackingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8cc206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test  = pd.read_csv('./data/test.csv')\n",
    "\n",
    "train['Source'] = 'train'\n",
    "test['Source']   = 'test'\n",
    "df = pd.concat([train, test], sort=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67e8820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "PassengerId       0\n",
      "Survived        418\n",
      "Pclass            0\n",
      "Name              0\n",
      "Sex               0\n",
      "Age             263\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Ticket            0\n",
      "Fare              1\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "Source            0\n",
      "dtype: int64\n",
      "\n",
      "Numeric summary statistics:\n",
      "       PassengerId    Survived       Pclass          Age        SibSp  \\\n",
      "count  1309.000000  891.000000  1309.000000  1046.000000  1309.000000   \n",
      "mean    655.000000    0.383838     2.294882    29.881138     0.498854   \n",
      "std     378.020061    0.486592     0.837836    14.413493     1.041658   \n",
      "min       1.000000    0.000000     1.000000     0.170000     0.000000   \n",
      "25%     328.000000    0.000000     2.000000    21.000000     0.000000   \n",
      "50%     655.000000    0.000000     3.000000    28.000000     0.000000   \n",
      "75%     982.000000    1.000000     3.000000    39.000000     1.000000   \n",
      "max    1309.000000    1.000000     3.000000    80.000000     8.000000   \n",
      "\n",
      "             Parch         Fare  \n",
      "count  1309.000000  1308.000000  \n",
      "mean      0.385027    33.295479  \n",
      "std       0.865560    51.758668  \n",
      "min       0.000000     0.000000  \n",
      "25%       0.000000     7.895800  \n",
      "50%       0.000000    14.454200  \n",
      "75%       0.000000    31.275000  \n",
      "max       9.000000   512.329200  \n",
      "\n",
      "Numeric features: ['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "Categorical features: ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked', 'Source']\n"
     ]
    }
   ],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nNumeric summary statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Identify\n",
    "numeric_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nNumeric features: {numeric_cols}\")\n",
    "print(f\"Categorical features: {categorical_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering (FE)\n",
    "\n",
    "# Extract Title and LastName\n",
    "df['Title']    = df['Name'].str.split(',').str[1].str.split('.').str[0].str.strip()\n",
    "df['LastName'] = df['Name'].str.split(',').str[0]\n",
    "\n",
    "# IsWomanOrBoy flag\n",
    "df['IsWomanOrBoy'] = ((df['Title'] == 'Master') | (df['Sex'] == 'female')).astype(int)\n",
    "\n",
    "# Group‐wise Age imputation (Sex × Survived from train)\n",
    "age_means = train.groupby(['Sex', 'Survived'])['Age'].mean()\n",
    "overall_sex_means = train.groupby('Sex')['Age'].mean()\n",
    "\n",
    "def fill_age(row):\n",
    "    if pd.isnull(row['Age']):\n",
    "        if row['Source'] == 'train':\n",
    "            return age_means.loc[(row['Sex'], row['Survived'])]\n",
    "        else:\n",
    "            return overall_sex_means.loc[row['Sex']]\n",
    "    return row['Age']\n",
    "\n",
    "df['Age'] = df.apply(fill_age, axis=1)\n",
    "\n",
    "# Create decade‐based buckets\n",
    "df['Age2']  = (df['Age'] // 10).astype(int)\n",
    "df['Fare2'] = (df['Fare'].fillna(0) // 10).astype(int)\n",
    "\n",
    "# Family size & alone flags\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "df['Alone'] = (df['FamilySize'] == 0).astype(int)\n",
    "\n",
    "# Cabin‐related features\n",
    "df['Deck'] = df['Cabin'].str[0].fillna('M')\n",
    "df['HasCabin'] = df['Cabin'].notnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bac36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label‐encode categoricals\n",
    "to_encode = ['Sex','Embarked','Title','LastName','Deck']\n",
    "label_encoders = {}\n",
    "for col in to_encode:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = df[col].fillna('Missing').astype(str)\n",
    "    le.fit(df[col])\n",
    "    df[col] = le.transform(df[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260a890e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "train_df = df[df['Source']=='train'].drop(['Source','Name','Ticket','Cabin'], axis=1)\n",
    "test_df  = df[df['Source']=='test'].drop(['Source','Name','Ticket','Cabin','Survived'], axis=1)\n",
    "\n",
    "X = train_df.drop('Survived', axis=1)\n",
    "y = train_df['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f842eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling Pipelines\n",
    "\n",
    "# Preprocessor\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler',  StandardScaler())\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, X_train.columns)\n",
    "])\n",
    "\n",
    "# Bagging\n",
    "bagging = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('clf', BaggingClassifier(estimator=DecisionTreeClassifier(),\n",
    "                              n_estimators=100, random_state=42))\n",
    "])\n",
    "bagging.fit(X_train, y_train)\n",
    "y_bag = bagging.predict(X_test)\n",
    "\n",
    "# AdaBoost\n",
    "boosting = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('clf', AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1),\n",
    "                               n_estimators=100, learning_rate=1.0, random_state=42))\n",
    "])\n",
    "boosting.fit(X_train, y_train)\n",
    "y_boost = boosting.predict(X_test)\n",
    "\n",
    "# Stacking\n",
    "estimators = [\n",
    "    ('lr', LogisticRegression(max_iter=2000, solver='liblinear')),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "]\n",
    "stacking = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('clf', StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(max_iter=2000, solver='liblinear'),\n",
    "        cv=5\n",
    "    ))\n",
    "])\n",
    "stacking.fit(X_train, y_train)\n",
    "y_stack = stacking.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c7780f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bagging Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88       105\n",
      "         1.0       0.83      0.81      0.82        74\n",
      "\n",
      "    accuracy                           0.85       179\n",
      "   macro avg       0.85      0.85      0.85       179\n",
      "weighted avg       0.85      0.85      0.85       179\n",
      "\n",
      "Boosting Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.88      0.85       105\n",
      "         1.0       0.81      0.74      0.77        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n",
      "Stacking Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.89      0.88       105\n",
      "         1.0       0.83      0.81      0.82        74\n",
      "\n",
      "    accuracy                           0.85       179\n",
      "   macro avg       0.85      0.85      0.85       179\n",
      "weighted avg       0.85      0.85      0.85       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Bagging', 'Boosting', 'Stacking'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_bag),\n",
    "        accuracy_score(y_test, y_boost),\n",
    "        accuracy_score(y_test, y_stack)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nBagging Report:\\n\", classification_report(y_test, y_bag))\n",
    "print(\"Boosting Report:\\n\", classification_report(y_test, y_boost))\n",
    "print(\"Stacking Report:\\n\", classification_report(y_test, y_stack))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
