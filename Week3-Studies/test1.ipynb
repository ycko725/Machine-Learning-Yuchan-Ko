{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (569, 30)\n",
      "Target shape: (569,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f27979ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "print(\"Attribute names:\", data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f26a5a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53d53af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24f4ae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per feature: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Missing values per feature:\", np.isnan(X).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8e2d611",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This would've been used if the data had missing values\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# imputer = SimpleImputer(strategy='mean')\n",
    "# X_imputed = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3a959aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc1f4856",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Encoding is not necessary for this dataset as it contains only numerical features.\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# y_encoded = le.fit_transform(y)\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# encoder = OneHotEncoder(sparse=False)\n",
    "# X_encoded = encoder.fit_transform(X_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e4a1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness\n",
      "0        17.99         10.38          122.80     1001.0          0.11840\n",
      "1        20.57         17.77          132.90     1326.0          0.08474\n",
      "2        19.69         21.25          130.00     1203.0          0.10960\n",
      "3        11.42         20.38           77.58      386.1          0.14250\n",
      "4        20.29         14.34          135.10     1297.0          0.10030\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "\n",
    "selected_features = [\n",
    "    'mean radius',\n",
    "    'mean texture',\n",
    "    'mean perimeter',\n",
    "    'mean area',\n",
    "    'mean smoothness'\n",
    "]\n",
    "\n",
    "df_selected = df[selected_features]\n",
    "print(df_selected.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c30a9abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier Cross-Validation Accuracy (mean): 0.9120\n",
      "Voting Classifier Test Accuracy: 0.9532\n",
      "Voting Classifier Test Recall: 0.9630\n",
      "Voting Classifier Test F1 Score: 0.9630\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "\n",
    "# Use selected features for training\n",
    "X_train_selected = X_train[:, [df.columns.get_loc(f) for f in [\n",
    "    'mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness'\n",
    "]]]\n",
    "X_test_selected = X_test[:, [df.columns.get_loc(f) for f in [\n",
    "    'mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness'\n",
    "]]]\n",
    "\n",
    "# Create pipelines for each classifier\n",
    "logreg = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', SVC(probability=False))\n",
    "])\n",
    "\n",
    "knn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "dtree = Pipeline([\n",
    "    ('clf', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "nb = Pipeline([\n",
    "    ('clf', GaussianNB())\n",
    "])\n",
    "\n",
    "# Create VotingClassifier with hard voting\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', logreg),\n",
    "        ('svm', svm),\n",
    "        ('knn', knn),\n",
    "        ('dt', dtree),\n",
    "        ('nb', nb)\n",
    "    ],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Cross-validation on training set\n",
    "cv_scores = cross_val_score(voting_clf, X_train_selected, y_train, cv=5)\n",
    "print(f\"Voting Classifier Cross-Validation Accuracy (mean): {cv_scores.mean():.4f}\")\n",
    "\n",
    "# Fit and evaluate on test set\n",
    "voting_clf.fit(X_train_selected, y_train)\n",
    "y_pred = voting_clf.predict(X_test_selected)\n",
    "\n",
    "test_accuracy = voting_clf.score(X_test_selected, y_test)\n",
    "test_recall = recall_score(y_test, y_pred)\n",
    "test_f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Voting Classifier Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Voting Classifier Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Voting Classifier Test F1 Score: {test_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
